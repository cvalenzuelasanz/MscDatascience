---
title: "Prediccion series temporales"
output:
  word_document: default
  html_document: default
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Wrangler

##read data from CSV file

Cargamos las librerias


```{r}
library(xts)
library(devtools)
library(ggplot2)
library(ggfortify)
library(quantmod) #Package to download financials historical data 
library(moments) # Calculate Kurstosis and skewness
library(plyr) #Using ddply with data.frames
library(zoo)
library(base)
library(tseries)
library(timsac)
library(TSA)
library(e1071)
```

Importamos los datos del directorio
```{r}
rawData <- read.csv("C:/Users/valen/Desktop/Master Datascience/Predicción/Clase05/Datos/apple.csv", sep=",", dec=".")
```

Reemplazamos los valores NA por ceros

```{r}
#Replace NA values
rawData <- rawData[-1,]
rawData[is.na(rawData)] <- 0
```

Sum the sales of iphone, ipad, ipod and mac in another column (Total Sales)
```{r}
rawData["Total_sales"] <- rowSums(rawData[, c(3:6)])
```

Transformamos la variable Time de cuatrimestre y año a año y cuatrimedtre


```{r}
rawData$Time <- as.yearqtr(rawData$Time, format = "Q%q/%y")
```

Transformamos nuestros datos a XTS (formato de serie temporal)

```{r}
xVentas <- xts((rawData$Total_sales),order.by=rawData$Time)
```

Transformamos los datos a formato zoo.

```{r}
zVentas <- as.zoo(xVentas)
names(zVentas)="Ventas"
```

Almacenamos en un Dataframe las ventas y los intervalos de tiempo para su posterior representacion grafica

```{r}
df_new <- data.frame(value = as.vector(zVentas),
                     time = time(zVentas))
```



#Representaciones gráficas

Serie

```{r}
autoplot(zVentas)+ylab("Sales")+ggtitle("Apple Sales")+xlab("Year")
```

Series por trimestres

```{r}
ggfreqplot(as.ts(zVentas),freq=4,nrow=1,facet.labeller=c("1Q","2Q","3Q","4Q"))+ggtitle("Quaterly sales")
```

Descripcion de la serie:
Tendencia: tiene tendencia positiva, no queda claro si es lineal o exponencial y no tiene componente ciclico.
Estacionalidad: Claramente existe componente estacional multiplicativo, como puede observarse en el primer trimestre de cada ano.
La serie es no estacionaria en varianza y media.


#Modelos ETS

Los modelos ETS solo asumen datos no estacionarios. 

Dentro de los modelos ETS, los que incluyen el componente estacional son los llamados  Holt-Winters. Vamos a estimar 4 modelos Holt-Winter y seleccionaremos el mejor en funcion de los criterios AIC, BIC y HQ.

##Separación de la serie en entrenamiento y test


```{r}
#Number of periods to forecast
cOmit=4

#Total number of periods
nObs=length(zVentas)

#Time series to train
oVentas <- window(zVentas,start=index(zVentas[1]),end=index(zVentas[nObs-cOmit]))
```

```{r}
library(forecast)
```


##Holt - modelo (A,N)
```{r}
fit_HWAN <- holt(oVentas)
fit_HWAN$model
```

##Holt- exponential (M,N)
```{r}
fit_HWMN <- holt(oVentas,exponential=TRUE)
fit_HWMN$model
```

##Holt - damped - modelo (Ad, N)

```{r}
fit_HWADN <- holt(oVentas,damped=TRUE)
fit_HWADN$model
```

##Holt - (exponential+damped) (Md,N)
```{r}
fit_HWMDN <- holt(oVentas,exponential=TRUE,damped=TRUE)
fit_HWMDN$model
```


##Representación gráfica

```{r}
plot(fit_HWAN,ylab="Ventas",
     plot.conf=FALSE, type="o", fcol="orange", xlab="Year")
lines(window(zVentas),type="o",col="blue")
lines(fitted(fit_HWAN), col="orange", lty=2)
lines(fitted(fit_HWADN), col="red", lty=2)
lines(fitted(fit_HWMN), col="green", lty=2)
lines(fitted(fit_HWMDN), col="black", lty=2)
lines(fit_HWADN$mean, type="o", col="red")
lines(fit_HWMN$mean, type="o", col="green")
lines(fit_HWMDN$mean, type="o", col="black")
legend("topleft",lty=1, pch=1, col=c("blue","orange", "red", "green", "black"), 
       c("data","HWAN", "HWADN","HWMN", "HWMDN"))
```


##Holt con comportamiento estacional aditivo

```{r}
fit_HWNA <- hw(oVentas,seasonal="additive")
fit_HWNA$model
```

##Holt con comportamiento estacional multiplicativo

```{r}
fit_HWNM <- hw(oVentas,seasonal="multiplicative")
fit_HWNM$model
```


Como se puede apreciar de todos los modelos ek que menor AIC tiene es el modelo con comportamiento estacional multiplicativo muy similar en cuanto al resultados al modelo con tendencia exponencial amortiguada.


##ETS automático

```{r}
etsfit<-ets(oVentas)
```


```{r}
coef(etsfit)
```

Devuelve los coeficientes del modelo

```{r}
fventas.ets=forecast(etsfit,level=(c(75,25)))
```

```{r}
summary(fventas.ets)
```

El ETS nos sugiere un modelo con errores multiplicativos, tendencia aditiva y Componente estacional multiplicativa.

```{r}
plot(fventas.ets)
lines(window(zVentas),type="o")
```

```{r}
matrix(c(fventas.ets$mean[1:cOmit],zVentas[(nObs-cOmit+1):nObs]),ncol=2)
#calculas los trimestres y los comparas con lo real, vemos que en el 4T es donde mas me alejo.
```

## Ets automático con amortiguamiento

```{r}
estfit2=ets(zVentas, damped=FALSE)
f.estfit2=forecast(estfit2)
plot(f.estfit2)
lines(fitted(fventas.ets), col="orange", lty=2)
lines(fventas.ets$mean, type="o", col="orange")
summary(f.estfit2)
```

#Modelos ARIMA

##Transformaciones de la serie original

Hacemos la transformación logarítmica para convertir la serie a estacionaria

```{r}
#Transformación de la serie
zlVentas=log(zVentas)
# Almacenamos en un nuevo dataframe
df_newl <- data.frame(value = as.vector(zlVentas),
                     time = time(zlVentas))
#Representación gráfica
ggplot(df_newl)+geom_point(aes(x=time,y=value))+geom_line(aes(x=time,y=value))+ylab("Ventas")+ggtitle("Ventas Trimestrales LOG Apple")+xlab("Trimestres")

```


```{r}
ggtsdisplay(zlVentas)
```

Como se puede observar graficamente hay una elavada autocorrelación parcial con respecto al periodo anterior y respecto a cuatro periodos anteriores.

Por ello vamos a representar como sería la diferencia con respecto a cuatro periodos anteriores (restar al trimestre anterior los cuatro trimestres anteriores)

```{r}
ggtsdisplay(diff(zlVentas,4))
```

Tras realizar esta transformación sigue habiendo autocorrelacion parcial de un periodo. Por ello calculamos la diferencia de un periodo respecto de la diferencia de cuatro periodos. (Diferencia de la tasa de variación interanual)

```{r}
ggtsdisplay(diff(diff(zlVentas,4),1))
```

Tras aplicar estas transformaciones tendriamos un modelo estacionario y ya podríamos hacer predicciones. 


Selección de observaciones de la muestra para entrenamiento y predicción

```{r}
#El comit es para quitar 6 observaciones de la muestra.
cOmit=6

#Data Size
nObs=length(zVentas)

#sub_sample
oVentas <- window(zVentas,start=index(zVentas[1]),end=index(zVentas[nObs-cOmit])) 
```


```{r}
#out sample (real data to forecast performance)
pVentas <- window(zVentas,start=index(zVentas[nObs-cOmit+1]),end=index(zVentas[nObs]))
```




## Primer modelo ARIMA

Estimamos el modelo ARIMA con la funcion autoarima y marcando lambda=0 para hacer una transformacion logaritmica a la serie

```{r}
fit1=auto.arima(oVentas,lambda=0)
summary(fit1)
```

Obtenemos un modelo SARIMA, es decir, un modelo ARIMA con componente estacional. 
Componente no estacional:
- Autocorrelacion de un periodo (un retardo)
Componente estacional:
- Diferencia de 4 periodos (al estar trabajando con trimestres), sería una diferencia anual. Transformaríamos la serie: Xt - Xt-4. La serie transformada sería la original menos el periodo trimestral del año anterior. 
- De esta serie transformada tendríamos correlación con respecto al periodo anterior.

Ambas nos indican que las ventas de un trimestre dependen de las ventas de hace un año y del trimestre anterior a este.

###Residuos

```{r}
ggtsdisplay(fit1$residuals)
```


Como se puede apreciar todos los residuos son ruido blanco lo que nos indica que efectivamente el modelo arima es totalmente estacionario y que los errores no dependen de los errores cometidos en periodos anteriores (son aleatorios)

###box-Ljung Test

```{r}
Box.test(fit1$residuals,lag=4, fitdf=3, type="Lj")
Box.test(fit1$residuals,lag=8, fitdf=3, type="Lj")
Box.test(fit1$residuals,lag=12, fitdf=3, type="Lj")
```

El test de Box - Ljung sirve para medir si los errores de nuestro modelo son ruido blanco. 

H0: Residuos son ruido blanco
H1: Residuos no son ruido blanco

El test de BOX para retardos de 4 periodos nos sugiere que los residuos no son ruido blanco al ser el pvalor inferior a un nivel de significación del 5% pero para retardos de 8 y 12 oeriodos si lo son, por tanto podemos concluir que los residuos si son aleatorios.

### Predicción y representacion grafica



```{r}
fventas.arima1=forecast(fit1)
```

Representacion grafica

```{r}
ggplot(df_new)+geom_point(aes(x=time,y=value))+geom_line(aes(x=time,y=value))+ geom_forecast(fventas.arima1,alpha=0.4)+ggtitle("ARIMA1: Predicción Apple")
```



El sombreado es el intervalo de confianza, la línea azul es la predicción y la negra son los datos reales.

```{r}
fventas.arima1
```



## Arima 2

Cambiamos dos parametros de la función autoarima introducimos Stepwise = False, lo que consigue es que busca entre todos los modelos por ello es mas exigente computacionalmente y approximation = FALSE, lo que evita que se hagan estimaciones sobre los errores y se estime para cada modelo la maxima verosimilitud.


```{r}
fit2=auto.arima(oVentas,lambda=0, stepwise=FALSE, approximation=FALSE)
summary(fit2)
```

Como se puede apreciar al haber cambiado los parámetros de la función el modelo Sarima que nos sugiere es distinto. ARIMA(1,0,3)(0,1,1)[4]

Componente no estacional:
- Autocorrelacion de un periodo (un retardo)
- Media movil de 3 periodos: los errores de predicción de un periodo dependen de los errores cometidos en los 3 periodos anteriores.
Componente estacional:
- Diferencia de 4 periodos (al estar trabajando con trimestres), sería una diferencia anual. Transformaríamos la serie: Xt - Xt-4. La serie transformada sería la original menos el periodo trimestral del año anterior. 
- De esta serie transformada, hay media movil de un periodo. Los errores dependen del error cometido en el periodo anterior de la serie transformada

###Residuos

```{r}
ggtsdisplay(fit2$residuals)
```


Como se puede apreciar todos los residuos son ruido blanco lo que nos indica que efectivamente el modelo arima es totalmente estacionario y que los errores no dependen de los errores cometidos en periodos anteriores (son aleatorios)

### Test de Box

```{r}
Box.test(fit2$residuals,lag=4, fitdf=3, type="Lj")
Box.test(fit2$residuals,lag=8, fitdf=3, type="Lj")
Box.test(fit2$residuals,lag=12, fitdf=3, type="Lj")

```


Como podemos apreciar con este nuevo modelo arima, nos sugiere que los residuos son ruido blanco para todos los retardos al ser los p-valores superiores a un nivel de significación de 5%, a diferencia del arima anterior que nos indicaba que no eran ruido blanco para 4 retardos.

### Prediccion y representacion grafica

```{r}
fventas.arima2=forecast(fit2)
```

```{r}
fventas.arima2
```

```{r}
ggplot(df_new)+geom_point(aes(x=time,y=value))+geom_line(aes(x=time,y=value))+ geom_forecast(fventas.arima1,alpha=0.4)+geom_forecast(fventas.arima2,alpha=0.5)+ggtitle("Comparativa Arima 1 y 2")

```

Como se puede apreciar graficamente el modelo Arima 2 predice bastante peor que el modelo Arima 1 a pesar de tener mejor AIC y mejores resultados en el test de Box. Por tanto nos quedaremos con el primer ARIMA



##Outliers

###Aditivos

```{r}
library(TSA)
```


Tiene valores atipicos aditivos el modelo?
```{r}
detectAO(fit1)
```
El modelo detecta 2 aditivos. Tendremos que comprobar si efectivamente se trata de outliers o, sin embargo, se trata de intervenciones.


###Innovativos
Tiene valores atipicos innovativos el modelo?
```{r}
detectIO(fit1)
```

Existe un valor atipico innovativo que hemos de eliminar. Los valores atipicos multiplicativos afectan al error y empeoran los modelos. 

Aditivo e innovativo al mismo tiempo

Por tanto utilizaremos la función arimax para quitar el outlier innovativo y aditivo del modelo Arima 1.
```{r}
Arimax1=arimax(oVentas,order=c(1,0,0),seasonal=list(order=c(1,1,0),period=4),
io=c(8))
Arimax1
```

# Conclusion

Como se puede apreciar empeora bastante el AIC del modelo por tanto nos quedamos con el modelo ARIMA 1 utilizado.
