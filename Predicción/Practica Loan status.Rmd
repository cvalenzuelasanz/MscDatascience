---
title: "Practica2 - credit risk and loan performance"
output:
  word_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```



El objetivo de esta practica es establecer un modelo que permita predecir si un prestamo hara default o no a partir de los datos de Lending Club (2007-2011). Tenemos que depurar los datos y trabajar con ellos para responder a las siguiente pregunta:

?cuales son las caracteristicas de los prestatarios que permiten determinar el riesgo de impago?

....
```{r}
rm(list=ls())
```


#Tratamiento de Datos

##Carga de Datos

```{r}

loandata<-read.csv("C:/Users/valen/Desktop/Master Datascience/Predicción/Predicción2/LoanStats3aSEP.csv", sep="|", dec=".", fill=T, header=T)
#View(loandata)

```


En una primera instancia nos quedamos con las variables de 2 a 47, puesto que a partir de la variable 48 los valores son NA.


```{r}
loandata<-loandata[,c(2:47)]
loandata_orig<-loandata
```

Quitamos las variables URL, month since last deliquency y month since last record puesto que los campos vienen vacíos.

```{r}
loandata<-loandata[,c(-18,-28,-29)]
```


Tras la lectura del artículo hemos considerado que las siguientes variables podrian interesarnos para explicar Default

- Interest Rate: tipo de interes del préstamo
- Installment: el pago mensual del prestatario
- grade: calificación crediticia del préstamo desde A a G. Siendo A la mejor calificación y G la peor.
- subgrade: calificación crediticia según Lending Club desde A1 a G5.
- annual income: los ingresos anuales reportados por el prestatario en el momento de la concesión del préstamo
- loan_status: el estado actual del préstamo. Se pueden agrupar entre Fully Paid (no default) y Charged OFF(Default)
- dti: porcentaje entre los pagos de deuda del individuo, excluyendo hipóteca y el préstamo solicitado, entre sus ingresos mensuales
- delinq_2yrs: el número de incumplimientos de pagos de deuda superiores a los 30 días, en los últimos dos años.
- inq_last_6mnths: número de solicitudes en los últimos 6 meses, excluyendo préstamos para coches e hipótecas.
- open_acc: número de líneas de crédito abiertas por el prestatario
- revol_bal: saldo de la línea de crédito
- revo_util: porcentaje de consumo de la línea de crédito
- total_acc: número de líneas de crédito en el historial del prestatario
- total_pyment: total de pagos realizados sobre el importe prestado

```{r}
loandata2<-loandata[,c(6:9,13,16,23,24,26,27,29,30,31,35)]
str(loandata2)

```

##Proceso de limpieza de la variable a explicar: loan_status

Vemos un resumen de los valores que toma la variable loan_status

```{r}
summary(loandata2$loan_status)
```

Como se puede apreciar en este variable hay algunas fechas, valores raros y vacíos.

A continuación elaboramos un bucle para eliminar del dataset aquellos prestamos cuyo Loanstatus es vacío.


```{r}

posiciones_vacio <- NULL
for (i in (1:length(loandata2$loan_status))){
        if (loandata2$loan_status[i]==""){
                posiciones_vacio <- c(posiciones_vacio,i)
        }
        
}

length(posiciones_vacio)
loandata2<-loandata2[-posiciones_vacio,]

```


Utilizamos la función revalue para cambiar los valores de Loanstatus.

- Does not meet the credit policy. Status:Fully Paid lo convertimos a Fully Paid
- Does not meet the credit policy. Status:Charged Off: lo convertimos a Charged Off
- Las fechas las convertimos todas a NA

```{r}
library(plyr)
loandata2$loan_status<-revalue(loandata2$loan_status, c("Does not meet the credit policy. Status:Fully Paid"="Fully Paid", "Does not meet the credit policy. Status:Charged Off"="Charged Off", "Aug-2010"="NA", "Jul-2010"="NA", "Mar-2011"="NA", "May-2011"="NA", "Nov-2011"="NA", "Oct-2010"="NA", "Sep-2011"="NA", "Dec-2010"="NA", "Dec-2011"="NA", "f"="NA", "Feb-2011"="NA"))

```


```{r}
loandata2$loan_status<-revalue(loandata2$loan_status,c("Feb-2011"="Fully Paid", "NA"="Fully Paid"))
```

?Como nos queda?
```{r}
summary(loandata2$loan_status)
```


##Limpiamos el resto de variables importantes

###dti

A continuación elaboramos un bucle para eliminar del dataset aquellos prestamos cuyo dti es vacío.

```{r}
posiciones_vacio <- NULL
posiciones_f <- NULL

for (i in (1:length(loandata2$dti))){
        if (loandata2$dti[i]==""){
                posiciones_vacio <- c(posiciones_vacio,i)
        }
        
}

head(posiciones_vacio)

loandata2<-loandata2[-posiciones_vacio,]



```



###delinq_2yrs

A continuación elaboramos un bucle para eliminar del dataset aquellos prestamos que en delinq_2yrs su valor sea vacío.
```{r}
posiciones_vacio <- NULL
posiciones_f <- NULL

for (i in (1:length(loandata2$delinq_2yrs))){
        if (loandata2$delinq_2yrs[i]==""){
                posiciones_vacio <- c(posiciones_vacio,i)
        }
        
}

head(posiciones_vacio)

loandata2<-loandata2[-posiciones_vacio,]
```


###revol_bal

A continuación elaboramos un bucle para eliminar del dataset aquellos prestamos que en revol_bal su valor sea vacío.

```{r}
posiciones_vacio <- NULL
posiciones_f <- NULL

for (i in (1:length(loandata2$revol_bal))){
        if (loandata2$revol_bal[i]==""){
                posiciones_vacio <- c(posiciones_vacio,i)
        }
        
}

head(posiciones_vacio)

loandata2<-loandata2[-posiciones_vacio,]
```


###revol_util

A continuación elaboramos un bucle para eliminar del dataset aquellos prestamos que en revol_util su valor sea vacío.
```{r}
posiciones_vacio <- NULL
posiciones_f <- NULL

for (i in (1:length(loandata2$revol_util))){
        if (loandata2$revol_util[i]==""){
                posiciones_vacio <- c(posiciones_vacio,i)
        }
        
}

head(posiciones_vacio)

loandata2<-loandata2[-posiciones_vacio,]
```


## Transformación de las variables de factor a númerico

¿De que tipo son mis datos?

```{r}
str(loandata2)
```


Como se puede apreciar todos los datos vienen expresados como factor por ello vamos a transformarlos a numéricos.
Para ello utilizamos la funcion as.numeric pero para que no cambie el valor tenemos que utilizar la función paste.

```{r}
typeof(loandata2$int_rate)
loandata2$int_rate = gsub("%", "",loandata2$int_rate)
head(loandata2$int_rate)


loandata2$revol_util= gsub("%", "",loandata2$revol_util)
head(loandata2$revol_util)

loandata2$dti<-as.numeric(paste(loandata2$dti))
loandata2$int_rate<-as.numeric(paste(loandata2$int_rate))
loandata2$revol_util<-as.numeric(paste(loandata2$revol_util))
loandata2$annual_inc<-as.numeric(paste(loandata2$annual_inc))
loandata2$total_acc<-as.numeric(paste(loandata2$total_acc))
loandata2$installment<-as.numeric(paste(loandata2$installment))
loandata2$delinq_2yrs<-as.numeric(paste(loandata2$delinq_2yrs))
loandata2$inq_last_6mths<-as.numeric(paste(loandata2$inq_last_6mths))
loandata2$open_acc<-as.numeric(paste(loandata2$open_acc))
loandata2$revol_bal<-as.numeric(paste(loandata2$revol_bal))
loandata2$total_pymnt<-as.numeric(paste(loandata2$total_pymnt))
```


A la hora de convertir las variables a numerico se generan algunos NAs, esto se debe a que se habrán introducido mal algunos datos por eso no los reconoce como números.

Los variables interest rate y revol_util al estar expresadas en porcentaje y haberlas convertido en n?mero las dividimos entre 100.
```{r}
loandata2$int_rate <- (loandata2$int_rate/100)
loandata2$revol_util <- (loandata2$revol_util/100)
```


```{r}
unique(loandata2$sub_grade)
unique(loandata2$grade)
```


###Eliminación de NAs y preparación del Dataset definitivo

Vemos un summary de los datos que tenemos:

```{r}
summary(loandata2)
```

Como se puede apreciar se han generado algunos NAs en las distints variables, si bien son muy pocos. Procedemos a eliminarlos del Dataset.

```{r}
loandata2 <- na.omit(loandata2)
```

Quitamos la variable subgrade del modelo

```{r}
loandata2 <- loandata2[,-4]
head(loandata2)
```

##Relación entre la variable grade y loan_status

Miramos la relacion entre Grade y Default

```{r}
library(ggplot2)
ggplot(loandata2, aes(grade)) + geom_bar(aes(fill=loan_status))

```



```{r}
library(dplyr)
library(purrr)
grafica_df <- data.frame(loandata2$grade,loandata2$loan_status)
grafica_df.pct <- grafica_df %>% group_by(loandata2$grade,loandata2$loan_status) %>%
        summarise(count=n()) %>%
        mutate(pct = round(count/sum(count),2))

grafica_df.pct
```


Podemos podemos observar como aumenta el % de prestamos que entran en default a medida que disminuye el rating.


#Elaboración de la regresión

Cargamos las librerías
```{r}
library(modelr)
library(dplyr)
library(purrr)
library(leaps)
```

Probamos a hacer la regresión con todos el Dataframe.
```{r}
step(glm(loan_status~., family = "binomial", data=loandata2),direction='backward')
```


Hacemos 10 kfolds, con 10 distintas muestras de entrenamiento y test.

```{r}
#Crossvalidation
set.seed(20171025)  # Run to replicate this post
folds <- crossv_kfold(loandata2, k = 10)
folds
```


```{r}
folds$test[[1]]
```


```{r}
folds$train[[1]]
```

Para cada uno de los 10 kfolds vamos a estimar una regresión de forma Backward (empieza con todas las variables y va quitando)

```{r}
folds <- folds %>%
  mutate(model = map(train, ~ step(glm(loan_status~., family = "binomial", data=.),direction='backward'))) %>%
  mutate(aic=map_dbl(model,AIC)) %>%
  mutate(deviance = map2_dbl(model, test, deviance))
  
```

De cada fold seleccionamos el id, aic y deviance

```{r}
folds %>%
  select(.id, aic, deviance)
```

#Como se puede comprobar el modelo que produce menos errores es el modelo 8 que es por tanto el que utilizaremos.


```{r}
folds$aic
```

Como podemos comprobar el modelo que presenta una menor AIC es el 1 que por tanto es el que vamos a seleccionar.

```{r}
folds$model[1]
```

Guardamos en un Dataframe la muestra que se ha utilizado para el entrenamiento en el modelo 1.
```{r}
df_train <- data.frame(folds$train[1])

head(df_train)
```


Cambiamos el nombre de las columnas quitando X1.
```{r}
names <- colnames(df_train)
names <- gsub('X1.','',names, fixed=TRUE)
colnames(df_train) <- names
```


Guardamos en un Dataframe la muestra que se ha utilizado para el test en el modelo 1


```{r}
df_test <- data.frame(folds$test[1])

head(df_test)
```

Cambiamos el nombre de las columnas quitando X1.
```{r}
names <- colnames(df_test)
names <- gsub('X1.','',names, fixed=TRUE)
colnames(df_test) <- names
```


Vamos a guardar el modelo 

```{r}
modelodef <- glm(formula = loan_status ~ int_rate + installment + grade + 
    annual_inc + dti + delinq_2yrs + open_acc + revol_bal + revol_util + 
    total_acc + total_pymnt, family = "binomial", data = df_train)
summary(modelodef)
```



##Predicción dentro y fuera de la muestra

###Dentro de la muestra(Training)

```{r}
hist(predict(modelodef,type="response"))

```

```{r}
table(predict(modelodef,type="response")>0.20)
```

Con un punto de corte de 0,20 en la muestra de entrenamiento habría 31.798 individuos con una probabilidad de Default inferior al 20% y 6.278 con probabilidad superior.

```{r}
prob.modelodf.insample <- predict(modelodef,type="response")
predicted_modelodf_insample <- predict(modelodef,type="response")>0.20
predicted_modelodf_insample <- as.numeric(predicted_modelodf_insample)
```


####Creamos la matriz de confusion

```{r}
matriz_confusion_train <- table(df_train$loan_status,predicted_modelodf_insample,dnn=c("Truth","Predicted"))
matriz_confusion_train <- as.data.frame(matriz_confusion_train)
filas <- c(1,4)
matriz_confusion_train <- matriz_confusion_train[-filas,]
matriz_confusion_train
```

Tasa de error
```{r}
Verdadero_positivo <- matriz_confusion_train$Freq[1]
Falso_positivo <- matriz_confusion_train$Freq[2]
Falso_negativo <- matriz_confusion_train$Freq[3]
Verdadero_negativo <- matriz_confusion_train$Freq[4]
Total <- sum(matriz_confusion_train$Freq)

Tasa_de_error <- (Falso_positivo+Falso_negativo)/Total
Tasa_de_error
```

Aciertos positivos y aciertos negativos

```{r}
aciertos_positivos <- Verdadero_positivo/(Verdadero_positivo + Falso_negativo)
aciertos_positivos
aciertos_negativos <- Verdadero_negativo/(Verdadero_negativo+Falso_positivo)
aciertos_negativos
```

Como podemos en la muestra de entrenamiento el modelo tiene una tasa de éxito muy alta con respecto a clasificar como Fully Paid a un individuo pero presenta una mayor tasa de error a la hora de clasificar como charged Off (Default).

Por tanto nuestro modelo no es muy efectivo a la hora de predecir los casos de Default. Lo que nos sugiere que se debe ser prudente a la hora de utilizar el mismo, seleccionando un criterio de corte prudente (cortaremos con probabilidades bajas).



###Fuera de la muestra(Test)


```{r}
hist(predict(modelodef,df_test,type="response"))

```

```{r}
table(predict(modelodef,df_test,type="response")>0.20)
```

Con un punto de corte de 0,20 en el TEST habría 3.554 individuos con una probabilidad de Default inferior al 20% y 677 con probabilidad superior.

```{r}
prob.modelodf.outsample <- predict(modelodef,df_test,type="response") 
predicted_modelodf_outsample <- predict(modelodef,df_test,type="response")>0.20
predicted_modelodf_outsample <- as.numeric(predicted_modelodf_outsample)
```


###Creamos la matriz de confusion

```{r}
matriz_confusion_test <- table(df_test$loan_status,predicted_modelodf_outsample,dnn=c("Truth","Predicted"))
matriz_confusion_test <- as.data.frame(matriz_confusion_test)
filas <- c(1,4)
matriz_confusion_test <- matriz_confusion_test[-filas,]
matriz_confusion_test
```

Tasa de error
```{r}
Verdadero_positivo <- matriz_confusion_test$Freq[1]
Falso_positivo <- matriz_confusion_test$Freq[2]
Falso_negativo <- matriz_confusion_test$Freq[3]
Verdadero_negativo <- matriz_confusion_test$Freq[4]
Total <- sum(matriz_confusion_test$Freq)

Tasa_de_error <- (Falso_positivo+Falso_negativo)/Total
Tasa_de_error
```


Aciertos positivos y aciertos negativos

```{r}
aciertos_positivos <- Verdadero_positivo/(Verdadero_positivo + Falso_negativo)
aciertos_positivos
aciertos_negativos <- Verdadero_negativo/(Verdadero_negativo+Falso_positivo)
aciertos_negativos
```

Como podemos en la muestra de entrenamiento el modelo tiene una tasa de éxito muy alta con respecto a clasificar como Fully Paid a un individuo pero presenta una mayor tasa de error a la hora de clasificar como charged Off (Default).

Por tanto nuestro modelo no es muy efectivo a la hora de predecir los casos de Default. Lo que nos sugiere que se debe ser prudente a la hora de utilizar el mismo, seleccionando un criterio de corte prudente (cortaremos con probabilidades bajas).


##Curva ROC

Representación de la curva ROC para fuera del training (TEST)
```{r}
library(verification)
roc.plot(df_test$loan_status == "Charged Off", prob.modelodf.outsample)
```


La curva de Roc nos sugiere que para a partir de un false alarm Rate de un 10% (proporcion de Falso negativo entre el total de valores negativos reales) con un respectivo Hit rate de un 80% (proporcion de verdaderos positivos sobre el total de valores positivos reales) crece de forma lenta. 

Por tanto a priori siendo conservadores a partir de un 20% de probabilidad deberíamos considerar como Charged Off o Default al individuo.


```{r}
roc.plot(df_test$loan_status == "Charged Off", prob.modelodf.outsample)$roc.vol
```


El área de nuestro modelo es un 0,90 al ser un número cercano a 1 nos indica de la bondad de nuestro modelo.


##Función de costes:

Definir el search grid desde 0.01 a 0.99
```{r}
searchgrid = seq(0.01, 0.99, 0.01)
```


El resultado es una matriz de 99 filas y 2 columnas, la primera columna contiene la cut-off p y la segunda el coste 

```{r}
result = cbind(searchgrid, NA)
```



```{r}
cost1 <- function(r, pi){
        weight1 = 10
        weight0 = 1
        c1 = (r=="Charged Off")&(pi<pcut) #logical vector - true if actual 1 but predict 0
        c0 = (r=="Fully paid")&(pi>pcut) #logical vector - true if actual 0 but predict 1
        return(mean(weight1*c1+weight0*c0))
}
```

in the cost function, both r and pi are vectors, r=truth, pi=predicted probability

```{r}
for(i in 1:length(searchgrid)) {
        pcut <- result[i,1]
        result[i,2] <- cost1(df_train$loan_status, prob.modelodf.insample) 
        }
```

```{r}
head(result)
```

```{r}
plot(result, ylab="Cost in Training Set")
```

#Conclusiones

Como se puede observar la función de costes sigue un comportamiento prácticamente lineal, es decir para mejorar el ratio de acierto se debe incurrir en un mayor coste.

Por ello nos resulta complicado tomar decisiones de corte en base a este criterio. Tendremos en cuenta la curva de Roc como criterio para seleccionar nuestro cut off o punto a partir del cual asignamos a un inviduo como Default. 

Tras el análisis del comportamiento de nuestra curva hemos decidio seleccionar el 20% como cutoff probability ya que en ese punto tenemos un alto porcentaje de acierto (80%) con un bajo porcentajr de falsa alarma (cercano al 10%). Adicionalmente nuestro ratio de acierto a la hora de clasificar un individuo como Default es de un 78% frente al 95% de clasificarlo correctamente como no Default. Por tanto también nos invita a ser prudentes a la hora de elegir la probabilidad de corte.

Finalmente para aumentar nuestro porcentaje de acierto tendríamos que reducir aún mas si cabe nuestra cutoff probabibility lo que implicaría tener un porcentaje de falsa alarma mucho mas alto, lo que supondría dejar de conceder préstamos a muchos individuos y por tanto reducir mucho el volumen de negocio negocio. 











