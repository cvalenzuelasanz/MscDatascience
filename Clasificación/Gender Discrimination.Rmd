---
title: "Gender discrimination"
output:
  word_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


#Importación fichero y comprobación estructura:

## Establecemos el directorio de trabajo

```{r}

setwd("C:/Users/valen/Desktop/Master Datascience/Técnicas de clasificación")

 
```

##Leemos la base de datos y comprobamos el encabezados

```{r}

gender <- read.csv("http://www.biz.uiowa.edu/faculty/jledolter/DataMining/GenderDiscrimination.csv", header = TRUE)
head(gender)
```

#División dataset en muestra de aprendizaje y validación

##Semilla aleatoria

```{r}
set.seed(100)
```

##Definimos una muestra aleatoria de aprendizaje del arbol

La muestra de aprendizaje será el 70% del dataset y la de validación el 30% restante

```{r}
train <- sample(nrow(gender), 0.7*nrow(gender))
```

## Data frame para la muestra de aprendizaje y otro para la muestra de validación

```{r}
df.train <- gender[train,]

df.validate <- gender[-train,]
```

## Vemos la distribucion de ambas muestras para ver si están balanceadas.

```{r}
table(df.train$Gender)

table(df.validate$Gender)
```

Como se puede comprobar las muestra de entrenamiento (df.train) y validación (df.validate) están balanceadas el ratio de mujeres sobre hombres es de aproximadamente 2.

#Creación del árbol

Para la creación del árbol utilizamos la librería rpart, en este caso estimaremos la variable Gender mediante las otras dos variables (Experiencie y Salary).

```{r}
library(rpart)

arbol <- rpart(Gender ~ ., data=df.train, method="class",
               parms=list(split="information"))

print(arbol)
```


Inicialmente el árbol queda distribuido en 7 divisiones.

#Reducción árbol


## Tabla de complejidad paramétrica
```{r}
arbol$cptable
```

La tabla paramétrica nos indica en que número de nodos se encuentra el menor error y la desviación típica o distribución de esos errores. Como se puede apreciar en el tamaño 2 el xerror y la desviación típica es inferior que en el resto.

## Representamos gráficamente la curva cp

```{r}
plotcp(arbol)
```


En nuestro caso, el error de predicción es más pequeño cuando el árbol de clasificación es de tamaño 2 (tiene solo un nodo de división), como se puede apreciar en el gráfico.

#Poda del árbol y comprobación de resultados

##Podamos el arbol a partir del párametro de complejidad

```{r}
arbol.podado <- prune(arbol, cp=.0348)
```


##Cargamos la librería para representar graficamente el árbol

```{r}
library(rpart.plot)

prp(arbol.podado, type = 2, extra = 104,
    fallen.leaves = TRUE, main="Decision Tree")
```
Habría un único criterio de decisión: salario. Con dos nodos, el primero para aquellos que tengan un salario inferior a 90.800 y el segundo para los que tenga un salario mayor o igual a 90.800. Los del primer nodo serán considerados mujeres y los del segundo hombres.

Seguidamente procedemos a predecir los resultados del árbol en la muestra de validación. Comprobaremos la diferencia entre los resultados predichos por el árbol con los reales de la muestra de validación para ver el porcentaje de errores. 

##Prediccion con la muestra de validación

```{r}
arbol.pred <- predict(arbol.podado, df.validate, type="class")

arbol.perf <- table(df.validate$Gender, arbol.pred,
                    dnn=c("Actual", "Predicted"))

arbol.perf
```

El número total de errores del árbol es de 15 (13 hombres que han sido predichos como mujeres y 2 mujeres que han sido predichas como hombres) sobre un total de 63 elementos de la muestra de validación. La tasa de errores de nuestro árbol es de aproximadamente un 23%, o lo que es lo mismo el árbol acertará, en media, un 77% de los casos.

```{r}
library(partykit)

plot(as.party(arbol.podado))
```


#Método alternativo: árboles basados en la inferencia

La diferencia de este método con el método anterior es que la selección de variables y decisiones no se realiza en base a medidas de puridad sino en la significatividad de algunos contrastes.

##Creación arbol

```{r}
library(party)


fit.ctree <- ctree(Gender~., data=df.train)

plot(fit.ctree, main="Conditional Inference Tree")

```

El árbol de decisión estimado mediante Inferencia condicional tendría dos divisiones y tres nodos. En primer lugar, divide la muestra de entrenamiento en función del salario (como en el método tradicional). Si el salario es superior a 90.600 los asigna como hombre, en el caso de que el salario sea inferior o igual a 90.600 lo divide a su vez en experiencia mayor o menor o igual a 7 años. De esta manera, si el salario es inferior a 90.600 y la experiencia es inferior o igual a 7 años los asigna como hombres y si la experiencia es mayor que 7 años como mujeres.

Seguidamente procedemos a predecir los resultados del árbol en la muestra de validación. Comprobaremos la diferencia entre los resultados predichos por el árbol con los reales de la muestra de validación para ver el porcentaje de errores. 

##Predicción resultados
```{r}
ctree.pred <- predict(fit.ctree, df.validate, type="response")

ctree.perf <- table(df.validate$Gender, ctree.pred,
                    dnn=c("Actual", "Predicted"))

ctree.perf
```

Como en el caso anterior, el número total de errores del árbol es de 15 (13 hombres que han sido predichos como mujeres y 2 mujeres que han sido predichas como hombres) sobre un total de 63 elementos de la muestra de validación. La tasa de errores de nuestro árbol es de aproximadamente un 23%, o lo que es lo mismo el árbol acertará, en media, un 77% de los casos.

#Interpretación y conclusiones

Mediante ambos métodos (tradicional o inferencia condicional) llegamos a los mismos resultados. Sin embargo, el método tradicional es más eficiente puesto que sólo utiliza un criterio de clasificación frente a los dos del condicional. Por otro lado el método de clasificación condicional nos va a ser de mayor ayuda a la hora de la interpretación económica.

Los resultados económicos de ambos modelos nos sugieren que los hombres en media tienen un salario superior a las mujeres, es decir, que existe discriminación salarial entre los hombres y las mujeres. Los dos modelos coinciden en predecir (si bien es cierto que con un nivel de error de un 23%), que cuando el salario es superior a 91.000 unidades monetarias aproximadamente, lo más adecuado es considerar a ese individuo como hombre. El modelo de inferencia condicional llega a un paso más y dentro de los individuos cuyo salario sea inferior a 91.000 unidades monetarias hace una división por los años de experiencia, de tal manera que si la experiencia es inferior a 7 años lo considera hombre y en caso contrario 7 mujer. Esto nos sugiere que los hombres que tienen un salario menor o igual que las mujeres es debido a que tienen menor experiencia o lo que es lo mismo para mismos niveles de experiencia, el nivel salarial del hombre en un 77% de los casos será superior. 
